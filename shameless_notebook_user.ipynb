{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "If running with GPT2-generated responses, you must first run `pip install transformers accelerate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_RESPONSES_GPT2 = True\n",
    "SOLVE_CAPTCHAS = False # Seemingly not required for this form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions \n",
    "from selenium.webdriver.support.select import Select \n",
    "from selenium_recaptcha_solver import RecaptchaSolver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "if GENERATE_RESPONSES_GPT2:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_people = pd.read_csv(\"fake_details/FakeNameGenerator.com.csv\")\n",
    "print(f\"Loaded {len(fake_people)} fake people\")\n",
    "\n",
    "# This dict has one entry per file in the 'fake_fields' folder\n",
    "fields_info = dict[str, list[str]]()\n",
    "for filepath in Path(\"fake_fields\").iterdir():\n",
    "    if filepath.suffix.lower() == \".txt\":\n",
    "        with filepath.open() as f:\n",
    "            lines = f.readlines()\n",
    "        fields_info[filepath.stem] = [line.strip() for line in lines]\n",
    "print(f\"Loaded {len(fields_info)} fields: {list(fields_info.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_browser_agent() -> str:\n",
    "    idx = np.random.choice(len(fake_people))\n",
    "    return fake_people['BrowserUserAgent'].iloc[idx]\n",
    "\n",
    "def get_random_fake_fields() -> pd.Series:\n",
    "    ser = pd.Series(index = fields_info.keys(), dtype=str)\n",
    "    for key, val in fields_info.items():\n",
    "        ser[key] = val[np.random.choice(len(val))]\n",
    "    return ser\n",
    "\n",
    "def pick_at_least_one(elements: list) -> np.ndarray:\n",
    "    n_to_pick = np.random.choice(len(elements)) + 1\n",
    "    return np.random.choice(elements, n_to_pick, replace=False)\n",
    "\n",
    "def random_chance(p: float = 0.5) -> bool:\n",
    "    return np.random.random() < p\n",
    "\n",
    "school_keywords = {'school', 'schools', 'university', 'college', 'academy', 'education', 'educational'}\n",
    "def is_probably_school(name: str) -> bool:\n",
    "    words = {w.replace(',', '') for w in name.lower().split()}\n",
    "    return len(school_keywords & words) > 0\n",
    "is_probably_school('wolris academy, for the beans'), is_probably_school('fuck the government of utah')\n",
    "\n",
    "def _get_fake_phone_number():\n",
    "    \"\"\"\n",
    "    Generates a realistic phone number with a Utah area code\n",
    "    \"\"\"\n",
    "    utah_area_codes = [\"801\", \"385\", \"435\"]\n",
    "    area_code = np.random.choice(utah_area_codes)\n",
    "    first_local_digit = str(np.random.choice(9) + 1) # Can't be zero\n",
    "    other_digits = ''.join(str(n) for n in np.random.choice(10, 6))\n",
    "    joiner = np.random.choice(['-', '.', '', ' '])\n",
    "    if random_chance(0.4):\n",
    "        area_code = f\"({area_code})\"\n",
    "    \n",
    "    digit_groups = [\"+1\"] if random_chance(0.2) else [] # Small chance of including country code\n",
    "    digit_groups.extend([\n",
    "        area_code,\n",
    "        f\"{first_local_digit}{other_digits[:2]}\",\n",
    "        other_digits[2:],\n",
    "    ])\n",
    "\n",
    "    return joiner.join(digit_groups)\n",
    "\n",
    "faker = Faker()\n",
    "def _get_fake_address():\n",
    "    addr_lines = faker.address().split('\\n')\n",
    "\n",
    "    # Sometimes just return one address line to spice things up a bit\n",
    "    do_single_address_line = random_chance(0.15)\n",
    "    if do_single_address_line or len(addr_lines) == 1:\n",
    "        return addr_lines[0]\n",
    "    \n",
    "    addr_line_1 = addr_lines[0]\n",
    "    addr_line_2 = addr_lines[1]\n",
    "    # Replace state with UT 95% of the time\n",
    "    if ',' in addr_lines[1] and random_chance(0.95):\n",
    "        # State abbreviation\n",
    "        comma_idx = addr_line_2.index(',')\n",
    "        addr_line_2 = addr_line_2[: comma_idx + 2] + 'UT' + addr_line_2[comma_idx + 4 :]\n",
    "\n",
    "        # Zip code\n",
    "        zip_code = np.random.choice(fields_info['zip_codes'])\n",
    "        space_idx = addr_line_2.rfind(' ')\n",
    "        addr_line_2 = addr_line_2[:space_idx + 1] + zip_code\n",
    "\n",
    "    return f\"{addr_line_1}, {addr_line_2}\"\n",
    "\n",
    "def subsample_string(s: str, max_letters = 5, min_letters = 3, chance_force_start_zero = 0.0):\n",
    "    n_letters = min(len(s), np.random.choice(max(len(s), max_letters - 1)) + min_letters)\n",
    "    start = np.random.choice(len(s) // 2)\n",
    "    start = max(0, min(start, len(s) - min_letters))\n",
    "    if random_chance(chance_force_start_zero):\n",
    "        start = 0\n",
    "    return s[start : start + n_letters]\n",
    "\n",
    "def _get_email_from_name(name: str) -> str:\n",
    "    # Get first and last name components\n",
    "    names = name.lower().split()\n",
    "    first_name = names[0]\n",
    "    last_name = names[1] if len(names) > 1 else first_name\n",
    "    first_name_component = subsample_string(first_name, min_letters=99 if random_chance(0.3) else 3, chance_force_start_zero=0.6)\n",
    "    last_name_component  = subsample_string(last_name,  min_letters=99 if random_chance(0.3) else 3, chance_force_start_zero=0.6)\n",
    "\n",
    "    # Optionally swap first and last name components\n",
    "    if random_chance(0.5):\n",
    "        first_name_component, last_name_component = last_name_component, first_name_component\n",
    "\n",
    "    # Optionally add numbers to last name component\n",
    "    if random_chance(0.25):\n",
    "        num = np.random.choice(100)\n",
    "        last_name_component = f\"{last_name_component}{num:00}\"\n",
    "\n",
    "    # Optionally capitalize first and last name components\n",
    "    if random_chance(0.2):\n",
    "        first_name_component = first_name_component.capitalize()\n",
    "    if random_chance(0.1):\n",
    "        last_name_component = last_name_component.capitalize()\n",
    "\n",
    "    # Get email name (combined first and last name components)\n",
    "    joiner = np.random.choice(['_', '-', ''], p=[0.4, 0.1, 0.5])\n",
    "    email_name = joiner.join([first_name_component, last_name_component])\n",
    "\n",
    "    # Optionally replace letters with numbers\n",
    "    mapping = {s : n for s, n in zip(\"aeoli\", \"43011\")}\n",
    "    final_letters = []\n",
    "    for letter in email_name:\n",
    "        if letter in mapping and random_chance(0.08):\n",
    "            final_letters.append(mapping[letter])\n",
    "        else:\n",
    "            final_letters.append(letter)\n",
    "    email_name = ''.join(final_letters)\n",
    "\n",
    "    # Choose domain\n",
    "    domain_name = np.random.choice(['gmail.com', 'outlook.com', 'byu.edu', 'utah.gov'], p=[0.75, 0.15, 0.05, 0.05])\n",
    "\n",
    "    return f\"{email_name}@{domain_name}\"\n",
    "\n",
    "def get_fake_identity() -> pd.Series:\n",
    "    name = faker.name()\n",
    "    return pd.Series(dict(\n",
    "        name = name,\n",
    "        phone = _get_fake_phone_number(),\n",
    "        address = _get_fake_address(),\n",
    "        email = _get_email_from_name(name),\n",
    "    ))\n",
    "\n",
    "def get_new_webdriver():\n",
    "    options = Options()\n",
    "    options.add_argument(f\"user-agent={get_random_browser_agent()}\")\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate GPT2 Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_RESPONSES_GPT2:\n",
    "    # Instantiate model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", padding_side='left')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Basic prompts (can make more complicated)\n",
    "    gpt_prompts = [\n",
    "        \"I saw a blue person enter the wrong bathroom. It was terrible.\",\n",
    "        \"There was a mean person using the wrong bathroom. It was so bad.\",\n",
    "    ] * 50\n",
    "    \n",
    "    # Helper for regenerating GPT nonsense\n",
    "    GPT_RESULTS = []\n",
    "    gpt_use_counter = 0\n",
    "    def regenerate_gpt_text():\n",
    "        global GPT_RESULTS, gpt_use_counter\n",
    "        gpt_use_counter = 0\n",
    "        GPT_RESULTS.clear()\n",
    "\n",
    "        tokenized = tokenizer(gpt_prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        gen_tokens = model.generate(\n",
    "            tokenized['input_ids'],\n",
    "            attention_mask = tokenized['attention_mask'],\n",
    "            do_sample=True,\n",
    "            temperature=0.8, # 0.9\n",
    "            max_length=100,\n",
    "        )\n",
    "        gen_text = tokenizer.batch_decode(gen_tokens)\n",
    "        for prompt, gen in zip(gpt_prompts, gen_text):\n",
    "            GPT_RESULTS.append(gen.replace('<|endoftext|>', '').removeprefix(prompt))\n",
    "\n",
    "    # Call once to create initial batch of GPT nonsense\n",
    "    regenerate_gpt_text()\n",
    "\n",
    "def get_random_fake_fields_GPT(regen_at: int = 100) -> pd.Series:\n",
    "    # Regenerate tokens after a while\n",
    "    global gpt_use_counter\n",
    "    if gpt_use_counter >= regen_at:\n",
    "        print(f\" -> Regenerating GPT text\")\n",
    "        regenerate_gpt_text()\n",
    "\n",
    "    # Get random fake fields and replace relevant ones with GPT results\n",
    "    gpt_fields = ['evidence', 'how', 'information', 'resolve', 'who']\n",
    "    gpt_results = [str(x) for x in np.random.choice(GPT_RESULTS, len(gpt_fields), replace=False)]\n",
    "    ser = get_random_fake_fields()\n",
    "    for gpt_field, gpt_result in zip(gpt_fields, gpt_results):\n",
    "        # Clean up the text a bit\n",
    "        gpt_result = gpt_result.strip()\n",
    "        final_punct_idx = max(gpt_result.rfind('.'), gpt_result.rfind('!')) + 1\n",
    "        if final_punct_idx == 0:\n",
    "            final_punct_idx = -1\n",
    "        gpt_result = gpt_result[:final_punct_idx]\n",
    "        ser[gpt_field] = gpt_result\n",
    "\n",
    "    gpt_use_counter += 1\n",
    "    return ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful info about various fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_MAIN_TEXT_FIELDS = [\n",
    "    # (field path, field name)\n",
    "    ('//*[@id=\"cd_q1\"]/div[1]', 'who'),\n",
    "    ('//*[@id=\"cd_q2\"]/div[1]', 'information'),\n",
    "    ('//*[@id=\"cd_q3\"]/div[1]', 'resolve'),\n",
    "    ('//*[@id=\"cd_q4\"]/div[1]', 'how'),\n",
    "    ('//*[@id=\"cd_q5\"]/div[1]', 'evidence'),\n",
    "]\n",
    "\n",
    "IDENTITY_TEXT_FIELDS = [\n",
    "    (\"00N1K00000fX1ND\", \"name\"),\n",
    "    (\"00N1K00000fXXY3\", \"address\"),\n",
    "    (\"00N1K00000fWywZ\", \"email\"),\n",
    "    (\"00N1K00000fWywe\", \"phone\"),\n",
    "]\n",
    "\n",
    "GOVT_CHECKBOXES = [\n",
    "    1, # Allowed trans people to use the correct facilities (probs the main one to troll here)\n",
    "    2, # Lewdness, voyeurism, etc.\n",
    "    # 3, # No Privacy compliance plan\n",
    "    4, # No single occupant facility\n",
    "    # 5, # Other violation\n",
    "]\n",
    "\n",
    "SCHOOL_CHECKBOXES = [\n",
    "    6, # Failed to provide equal opportunity for boys & girls\n",
    "    7, # Allowed trans people to play on the correct team\n",
    "    8, # Allowed trans people to use the correct facilities\n",
    "    # 9, # Didn't tell students / parents about this dumbass law's policies lol\n",
    "]\n",
    "\n",
    "ALLOW_IDENTITY_DISCLOSURE_CHECKBOX_ID = \"00N1K00000fXXXy\"\n",
    "GOVERNMENT_ENTITY_DROPDOWN_ID = \"00N1K00000fGn13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "vprint = print if VERBOSE else lambda x: None\n",
    "\n",
    "DRIVER_USES_BEFORE_RESET = 6 # Tends to speed things up a bit because Chrome doesn't have to be restarted each time\n",
    "\n",
    "score = 0\n",
    "driver_use_counter = 0\n",
    "driver = get_new_webdriver()\n",
    "while True:\n",
    "    # Start new webdriver or use one from previous loop iteration (resets every DRIVER_USES_BEFORE_RESET)\n",
    "    if driver_use_counter >= DRIVER_USES_BEFORE_RESET:\n",
    "        driver_use_counter = 0\n",
    "        driver.close()\n",
    "        driver = get_new_webdriver()\n",
    "    driver.get(\"https://ut-sao-special-prod.web.app/sex_basis_complaint2.html\")\n",
    "    driver.maximize_window()\n",
    "    driver_use_counter += 1\n",
    "    solver = RecaptchaSolver(driver=driver)\n",
    "\n",
    "    # Check if everything's loaded correctly\n",
    "    fails = 0\n",
    "    while True:\n",
    "        try:\n",
    "            dropdown = driver.find_element(By.XPATH, '//*[@id=\"form-row\"]/form/div[1]/button').click()\n",
    "            break\n",
    "        except:\n",
    "            fails += 1\n",
    "            vprint(f\" -> Failed to load page {fails} time{'s' if fails > 1 else ''}\")\n",
    "            time.sleep(0.5)\n",
    "    vprint(\" -> Page successfully loaded!\")\n",
    "\n",
    "    # Generate random text & govt entity results for this entry\n",
    "    random_field_entries = get_random_fake_fields_GPT() if GENERATE_RESPONSES_GPT2 else get_random_fake_fields()\n",
    "    \n",
    "    # Select a government entity to report\n",
    "    dropdown = driver.find_element(By.ID, GOVERNMENT_ENTITY_DROPDOWN_ID)\n",
    "    dropdown_options = dropdown.get_property(\"options\")\n",
    "    random_entity = np.random.choice(dropdown_options[1:]).get_property(\"value\")\n",
    "    Select(dropdown).select_by_value(random_entity)\n",
    "\n",
    "    # Determine checkboxes to check\n",
    "    cb_ids_to_check = []\n",
    "    # Always check at least one school-unrelated checkbox\n",
    "    cb_ids_to_check.extend([f'cb{n}' for n in pick_at_least_one(GOVT_CHECKBOXES)])\n",
    "    # If entity is a school, check at least one school-related checkbox\n",
    "    if is_probably_school(random_entity):\n",
    "        cb_ids_to_check.extend([f'cb{n}' for n in pick_at_least_one(SCHOOL_CHECKBOXES)])\n",
    "    # Optionally check identity disclosure checkbox \n",
    "    if random_chance():\n",
    "        cb_ids_to_check.append(ALLOW_IDENTITY_DISCLOSURE_CHECKBOX_ID)\n",
    "\n",
    "    # Actually check the boxes\n",
    "    for cb_id in cb_ids_to_check:\n",
    "        cb_input = driver.find_element(By.ID, cb_id)\n",
    "        action = ActionChains(driver)\n",
    "        action.move_to_element(cb_input).perform()\n",
    "        action.click(cb_input).perform()\n",
    "\n",
    "    # Fill in all the big text fields\n",
    "    for field_path, field_name in REPORT_MAIN_TEXT_FIELDS:\n",
    "        field_box = driver.find_element(By.XPATH, field_path)\n",
    "        field_box.send_keys(random_field_entries[field_name])\n",
    "\n",
    "    # Fill in name, email, phone number\n",
    "    fake_identity = get_fake_identity()\n",
    "    for field_id, field_name in IDENTITY_TEXT_FIELDS:\n",
    "        field_box = driver.find_element(By.ID, field_id)\n",
    "        field_box.send_keys(fake_identity[field_name])\n",
    "\n",
    "    # Check the final acknowledgement checkboxes\n",
    "    ack1 = driver.find_element(By.ID, \"check_certify\");\n",
    "    action.move_to_element(ack1).perform()\n",
    "    action.click(ack1).perform()\n",
    "\n",
    "    ack2 = driver.find_element(By.ID, \"check_certify_2\");\n",
    "    action.move_to_element(ack2).perform()\n",
    "    action.click(ack2).perform()\n",
    "\n",
    "    # Solve CAPTCHA (seems slightly buggy; tends to crash)\n",
    "    if SOLVE_CAPTCHAS:\n",
    "        try:\n",
    "            recaptcha_iframe = driver.find_element(By.XPATH, '//*[@id=\"form-row\"]/form/div[30]/div/div/iframe')\n",
    "            action.move_to_element(recaptcha_iframe).perform()\n",
    "            solver.click_recaptcha_v2(iframe=recaptcha_iframe)\n",
    "        except TimeoutException as err:\n",
    "            print(f\" -> CAPTCHA TimeoutException: {err}\")\n",
    "        break\n",
    "\n",
    "    # SUBMIT!\n",
    "    submit = driver.find_element(By.ID, \"btn-submit-complaint2\");\n",
    "    action.move_to_element(submit).perform()\n",
    "    action.click(submit).perform()\n",
    "    time.sleep(2)\n",
    "    score = score + 1\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
